---
layout: page
title: Tell What You Hear From What You See
description: <b>Xiulong Liu</b>, Kun Su, Eli Shlizerman <b>NEURIPS 2024</b>
img: assets/img/vatt_teaser.png
importance: 1
category: work
---

<button onclick="location.href='https://www.youtube.com/watch?v=PDkbeiCc-kM'" type="button">
         Video</button>
<button onclick="location.href='https://proceedings.neurips.cc/paper_files/paper/2024/file/b782a3462ee9d566291cff148333ea9b-Paper-Conference.pdf'" type="button">
       Paper</button>

<div class="row">
   <div class="col-sm mt-3 mt-md-0">
       {% responsive_image path: assets/img/vatt_system_overview.png title: "example image" class: "img-fluid rounded z-depth-1" %}
   </div>
</div>
<div class="caption">
   <b>VATT: a general multi-modal audio generation framwork that can generate a wide of variety sounds by taking visual (and / or) text as inputs.</b>
</div>
