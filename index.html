<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Xiulong  Liu


</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üî•</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">


<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>



  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item dropdown ">
              <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                submenus
                
              </a>
              <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
              
              
                <a class="dropdown-item" href="/publications/">publications</a>
              
              
              
                <div class="dropdown-divider"></div>
              
              
              
                <a class="dropdown-item" href="/projects/">projects</a>
              
              
              </div>
          </li>
          
          
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Xiulong</span>  <span class="font-weight-bold">Liu
    </span>
</h1>
     <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        


<img class="img-fluid z-depth-1 rounded" src="/assets/resized/prof_pic-480x480.jpg" srcset="    /assets/resized/prof_pic-480x480.jpg 480w,/assets/img/prof_pic.jpg 800w">

      
      
        <div class="address">
          <!-- <p>EEB433, Department of Electrical Engineering </p> <p>University of Washington</p> <p>Seattle, WA 98195</p> -->
        </div>
      
    </div>
    

    <div class="clearfix">
      <p>I am Xiulong Liu, a Ph.D. graduate from the University of Washington, where I conducted research in the NeuroAI Lab under the supervision of Prof. <a href="https://faculty.washington.edu/shlizee/" target="_blank" rel="noopener noreferrer">Eli Shlizerman</a>. My research interests broadly lie in computer vision, audio generation and multi-modal learning. Prior to that, I received my B.S. degree in Electrical Engineering at Shanghai Jiaotong University.</p>

<!-- Write your biography here. Tell the world about yourself. Link to your favorite [subreddit](http://reddit.com). You can put a picture in, too. The code is already in, just name your picture `prof_pic.jpg` and put it in the `img/` folder. -->

<!-- Put your address / P.O. box / other info right below your picture. You can also disable any these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically. -->

<!-- Link to your social media connections, too. This theme is set up to use [Font Awesome icons](http://fortawesome.github.io/Font-Awesome/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them. -->

    </div>

    
      <div class="news">
  <h2>News</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">May 22, 2025</th>
          <td>
            
              I have successfully defended my PhD thesis titled ‚ÄúTowards Multi-modal Interactive Systems that Connects Audio, Vision and Beyond‚Äù and become Dr. Dragon!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Feb 26, 2025</th>
          <td>
            
              My first authored paper ‚Äú<a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Hearing_Anywhere_in_Any_Environment_CVPR_2025_paper.pdf" target="_blank" rel="noopener noreferrer">Hearing Anywhere in Any Environment</a>‚Äù has been accepted to <strong>CVPR 2025</strong>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Feb 10, 2025</th>
          <td>
            
              I pass my PhD General Exam, and become a Ph.D. candidate!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Sep 25, 2024</th>
          <td>
            
              My first authored paper ‚ÄúTell What You Hear From What You See - Video to Audio Generation Through Text‚Äù has been accepted by NeurIPS 2024!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Feb 26, 2024</th>
          <td>
            
              My first co-authored paper ‚ÄúMuseChat: A Conversational Music Recommendation System for Videos‚Äù has been accepted by CVPR 2024 as Highlight Poster (Top 2.8%)!

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CVPR</abbr>
    
  
  </div>

  <div id="Liu_2025_CVPR" class="col-sm-8">
    
      <div class="title">Hearing Anywhere in Any Environment</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Liu, Xiulong</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kumar, Anurag,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Calamia, Paul,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Amengual, Sebastia V.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Murdock, Calvin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ananthabhotla, Ishwarya,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Robinson, Philip,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shlizerman, Eli,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ithapu, Vamsi Krishna,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Gao, Ruohan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR)</em>
      
      
        Jun
      
      
        2025
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Liu_2025_CVPR</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{CVPR}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Xiulong and Kumar, Anurag and Calamia, Paul and Amengual, Sebastia V. and Murdock, Calvin and Ananthabhotla, Ishwarya and Robinson, Philip and Shlizerman, Eli and Ithapu, Vamsi Krishna and Gao, Ruohan}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hearing Anywhere in Any Environment}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5732-5741}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NEURIPS</abbr>
    
  
  </div>

  <div id="liu2024vatt" class="col-sm-8">
    
      <div class="title">Tell What You Hear From What You See - Video to Audio Generation Through Text</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Liu, Xiulong</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Su, Kun,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Shlizerman, Eli
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems</em>
      
      
      
        2024
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">liu2024vatt</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NEURIPS}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Xiulong and Su, Kun and Shlizerman, Eli}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Globerson, A. and Mackey, L. and Belgrave, D. and Fan, A. and Paquet, U. and Tomczak, J. and Zhang, C.}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{101337--101366}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Tell What You Hear From What You See - Video to Audio Generation Through Text}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://proceedings.neurips.cc/paper_files/paper/2024/file/b782a3462ee9d566291cff148333ea9b-Paper-Conference.pdf}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{37}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICML</abbr>
    
  
  </div>

  <div id="su2024vision" class="col-sm-8">
    
      <div class="title">From Vision to Audio and Beyond: A Unified Model for Audio-Visual Representation and Generation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Su, Kun,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Liu, Xiulong</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Shlizerman, Eli
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 41st International Conference on Machine Learning</em>
      
      
        21‚Äì27 jul
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Video encompasses both visual and auditory data, creating a perceptually rich experience where these two modalities complement each other. As such, videos are a valuable type of media for the investigation of the interplay between audio and visual elements. Previous studies of audio-visual modalities primarily focused on either audio-visual representation learning or generative modeling of a modality conditioned on the other, creating a disconnect between these two branches. A unified framework that learns representation and generates modalities has not been developed yet. In this work, we introduce a novel framework called Vision to Audio and Beyond (VAB) to bridge the gap between audio-visual representation learning and vision-to-audio generation. The key approach of VAB is that rather than working with raw video frames and audio data, VAB performs representation learning and generative modeling within latent spaces. In particular, VAB uses a pre-trained audio tokenizer and an image encoder to obtain audio tokens and visual features, respectively. It then performs the pre-training task of visual-conditioned masked audio token prediction. This training strategy enables the model to engage in contextual learning and simultaneous video-to-audio generation. After the pre-training phase, VAB employs the iterative-decoding approach to rapidly generate audio tokens conditioned on visual features. Since VAB is a unified model, its backbone can be fine-tuned for various audio-visual downstream tasks. Our experiments showcase the efficiency of VAB in producing high-quality audio from video, and its capability to acquire semantic audio-visual features, leading to competitive results in audio-visual retrieval and classification.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">su2024vision</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ICML}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{From Vision to Audio and Beyond: A Unified Model for Audio-Visual Representation and Generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Su, Kun and Liu, Xiulong and Shlizerman, Eli}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 41st International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{46804--46822}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{235}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{21--27 Jul}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CVPR</abbr>
    
  
  </div>

  <div id="Dong_2024_CVPR" class="col-sm-8">
    
      <div class="title">MuseChat: A Conversational Music Recommendation System for Videos</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Dong, Zhikang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Liu, Xiulong</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chen, Bin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Polak, Pawel,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Zhang, Peng
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>
      
      
        Jun
      
      
        2024
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Dong_2024_CVPR</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{CVPR}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dong, Zhikang and Liu, Xiulong and Chen, Bin and Polak, Pawel and Zhang, Peng}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MuseChat: A Conversational Music Recommendation System for Videos}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{12775-12785}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">AAAI</abbr>
    
  
  </div>

  <div id="Liu_Paul_Chatterjee_Cherian_2024" class="col-sm-8">
    
      <div class="title">CAVEN: An Embodied Conversational Agent for Efficient Audio-Visual Navigation in Noisy Environments</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Liu, Xiulong</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Paul, Sudipta,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chatterjee, Moitreya,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Cherian, Anoop
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>
      
      
        Mar
      
      
        2024
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Liu_Paul_Chatterjee_Cherian_2024</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{AAAI}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{CAVEN: An Embodied Conversational Agent for Efficient Audio-Visual Navigation in Noisy Environments}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{38}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ojs.aaai.org/index.php/AAAI/article/view/28167}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1609/aaai.v38i4.28167}</span><span class="p">,</span>
  <span class="na">abstractnote</span> <span class="p">=</span> <span class="s">{Audio-visual navigation of an agent towards locating an audio goal is a challenging task especially when the audio is sporadic or the environment is noisy. In this paper, we present CAVEN, a Conversation-based Audio-Visual Embodied Navigation framework in which the agent may interact with a human/oracle for solving the task of navigating to an audio goal. Specifically, CAVEN is modeled as a budget-aware partially observable semi-Markov decision process that implicitly learns the uncertainty in the audio-based navigation policy to decide when and how the agent may interact with the oracle. Our CAVEN agent can engage in fully-bidirectional natural language conversations by producing relevant questions and interpret free-form, potentially noisy responses from the oracle based on the audio-visual context. To enable such a capability, CAVEN is equipped with: i) a trajectory forecasting network that is grounded in audio-visual cues to produce a potential trajectory to the estimated goal, and (ii) a natural language based question generation and reasoning network to pose an interactive question to the oracle or interpret the oracle‚Äôs response to produce navigation instructions. To train the interactive modules, we present a large scale dataset: AVN-Instruct, based on the Landmark-RxR dataset. To substantiate the usefulness of conversations, we present experiments on the benchmark audio-goal task using the SoundSpaces simulator under various noisy settings. Our results reveal that our fully-conversational approach leads to nearly an order-of-magnitude improvement in success rate, especially in localizing new sound sources and against methods that use only uni-directional interaction.}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proceedings of the AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Xiulong and Paul, Sudipta and Chatterjee, Moitreya and Cherian, Anoop}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3765-3773}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">WACV</abbr>
    
  
  </div>

  <div id="Liu_2024_WACV" class="col-sm-8">
    
      <div class="title">Let the Beat Follow You - Creating Interactive Drum Sounds From Body Rhythm</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Liu, Xiulong</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Su, Kun,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Shlizerman, Eli
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>
      
      
        Jan
      
      
        2024
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Liu_2024_WACV</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{WACV}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Xiulong and Su, Kun and Shlizerman, Eli}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Let the Beat Follow You - Creating Interactive Drum Sounds From Body Rhythm}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{7187-7197}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">WACV</abbr>
    
  
  </div>

  <div id="liu2024tackling" class="col-sm-8">
    
      <div class="title">Tackling Data Bias in MUSIC-AVQA: Crafting a Balanced Dataset for Unbiased Question-Answering</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Liu, Xiulong</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dong, Zhikang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Zhang, Peng
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</em>
      
      
      
        2024
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">liu2024tackling</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{WACV}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Tackling Data Bias in MUSIC-AVQA: Crafting a Balanced Dataset for Unbiased Question-Answering}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Xiulong and Dong, Zhikang and Zhang, Peng}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4478--4487}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NEURIPS</abbr>
    
  
  </div>

  <div id="su2021howdoesitsound" class="col-sm-8">
    
      <div class="title">How Does it Sound? Generation of Rhythmic Soundtracks for Human Movement Videos</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Su, Kun*,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Liu, Xiulong*,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Shlizerman, Eli
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Advances in Neural Information Processing Systems</em>
      
      
      
        2021
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">su2021howdoesitsound</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NEURIPS}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{How Does it Sound? Generation of Rhythmic Soundtracks for Human Movement Videos}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Su, Kun* and Liu, Xiulong* and Shlizerman, Eli}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NEURIPS</abbr>
    
  
  </div>

  <div id="su2020audeo" class="col-sm-8">
    
      <div class="title">Audeo: Audio generation for a silent performance video</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Su, Kun,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Liu, Xiulong</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Shlizerman, Eli
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Advances in Neural Information Processing Systems</em>
      
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">su2020audeo</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NEURIPS}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Audeo: Audio generation for a silent performance video}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Su, Kun and Liu, Xiulong and Shlizerman, Eli}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{33}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CVPR</abbr>
    
  
  </div>

  <div id="su2020predict" class="col-sm-8">
    
      <div class="title">Predict &amp; cluster: Unsupervised skeleton based action recognition</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Su, Kun,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Liu, Xiulong</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Shlizerman, Eli
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>
      
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">su2020predict</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{CVPR}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Predict \&amp; cluster: Unsupervised skeleton based action recognition}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Su, Kun and Liu, Xiulong and Shlizerman, Eli}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{9631--9640}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
</ol>
</div>

    

    
    <div class="social">
      <div class="contact-icons">
        <a href="mailto:%6C%69%75%78%69%75%6C%6F%6E%67%31%39%39%35@%67%6D%61%69%6C.%63%6F%6D"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=e5GPhrMAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/DragonLiu1995" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/xiulong-liu-33040a130" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>














      </div>
      <div class="contact-note">Please feel free to reach out to me by email.
</div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    ¬© Copyright 2025 Xiulong  Liu.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>.

    
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  





</html>
